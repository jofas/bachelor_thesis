\documentclass[twoside,11pt]{article}
\usepackage{jmlr2e}
\usepackage{amsmath}
\usepackage[page]{appendix}
\usepackage{xcolor}
\usepackage[marginparsep=30pt]{geometry}
\usepackage{stmaryrd}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{tikz}
\usepackage{tabu}
\usepackage{listings}
\usepackage{fancyref}
\usepackage{relsize}

\usetikzlibrary{%
    arrows,
    arrows.meta,
    decorations,
    backgrounds,
    positioning,
    fit,
    petri,
    shadows,
    datavisualization.formats.functions,
    calc,
    shapes,
    shapes.multipart,
    matrix
}

\begin{document}
% titlepage {{{
\begin{titlepage}
  \begin{flushleft}
	\vspace*{-1cm}
	\includegraphics[scale=0.05]{TH.png}\\
	\vspace*{1cm}
\end{flushleft}
\begin{center}
\begin{LARGE}
\textbf{%
	Approximating the optimal threshold for an abstaining
  classifier based on a reward function with regression
}
\end{LARGE}
~\\
~\\
~\\
\textit{{\LARGE B}ACHELOR {\LARGE T}HESIS}
~\\
~\\
~\\
\begin{Large}
\begin{tabu} to \textwidth {Xr}
Jonas Fassbender
&\href{mailto:jonas@fassbender.dev}{jonas@fassbender.dev}\\
&11117674
\end{tabu}
\end{Large}
~\\
~\\
~\\
\begin{large}
In the course of studies

\textit{{\Large C}OMPUTER {\Large S}CIENCE}
~\\
~\\
~\\
For the degree of

\textit{{\Large B}ACHELOR OF {\Large S}CIENCE}
~\\
~\\
~\\
Technical University of Cologne

Faculty of Computer Science and Engineering
~\\
~\\
~\\
\begin{tabular}{rl}
  First supervisor: &Prof. Dr. Heinrich Klocke\\
                    &Technical University of Cologne\\
  &\\
  Second supervisor: &Prof. Dr. Fotios Giannakopoulos\\
                     &Technical University of Cologne
\end{tabular}
~\\
~\\
~\\
Overath, July 2019
\end{large}
\end{center}
\end{titlepage}
% }}}

%\begin{abstract}%
%\end{abstract}

%\begin{keywords}
%\end{keywords}

\section{Introduction}

An abstaining classifier
\citep[see e.g.][]{vanderlooy_et_al_2009}---also called a
classifier with reject option
\citep[see e.g.][]{fisher_et_al_2016}---is a kind
of confidence predictor.
It can refuse from making a prediction if its confidence in
the prediction is not high enough.
High enough, in this context, means that the confidence is
greater than a certain---hopefully optimal---threshold.
Optimality is dependent on a performance metric set
beforehand.

This thesis introduces a new kind of method for
approximating the optimal threshold based on a reward
function---better known from reinforcement learning than
from the supervised learning setting
\citep[see e.g.][]{sutton_et_al_2018}.
The method treats the reward function as unknown, making it
a very general approach and giving quite the amount of
freedom in designing the reward function.

In supervised learning the concept that is closest to a
reward function is a cost function and many abstract types
of cost in supervised learning are known
\citep[see][]{turney_2000}.

Probably today's most used methods for obtaining the
optimal threshold for reducing the expected cost of an
abstaining classifier are based on the receiver operating
characteristic (ROC) rule
\citep[see][]{tortella_2000,pietraszek_2005,
  vanderlooy_et_al_2009, guan_et_al_2018}.

The method presented in this thesis is more flexible than
the methods based on the ROC rule and can---depending on
the context of the classification problem---produce results
better interpretable (see Chapter~\ref{sec:example}).
Also it is more natural with multi-class classification
problems than the methods based on the ROC rule, all
assuming binary classification problems, wherefore the
classifiers generated by these methods must be transformed
to multi-class classifiers for non-binary problems.

On the other hand the presented method can suffer from its
very general approach and only produces approximations.
This can result in non-optimal and unstable thresholds.

This thesis first presents a motivational example.
In Chapter~\ref{sec:method} the proposed method is
presented.
After that experiments on data sets from the UCI machine
learning repository are discussed \citep[see][]{uci}.
At last further research ideas are listed and a conclusion
is drawn.

\section{Motivational example}
\label{sec:example}
Abstaining classifiers---compared to typical classifiers,
which classify every prediction---can be easily
integrated into processes where they partially replace the
decision making, since they can delegate the abstained
predictions back to the underlying process.
This is a valuable property if there does not exist a
typical classifier good enough to fully replace the
underlying process.

Many real world application domains for abstaining
classifiers can express a cost function associated to the
decisions about predicting and abstaining of the
classifier---which then chooses the threshold with which it
produces the least amount of cost, therefore minimizing
the cost.

For example, the real world application domain could be a
facial recognition system at a company which regulates
which employee can enter a trust zone and which can not.
In this example, the cost for miss-classifying an
unauthorized person as authorized can have huge costs for
the company while abstaining or classifying an authorized
employee as unauthorized produces quite low costs---the
authorized employee just has to start the manual process,
which should be replaced by the facial recognition system.

On the other hand, for some real world application domains
a reward function based on which the abstaining classifier
chooses the threshold by maximizing the reward---rather
than minimizing the cost---comes more natural.

Such a domain would be the finance industry,
where we often can associate a certain amount of money an
abstaining classifier can produce or safe by supporting the
decision making of an underlying process.

An example for such a process would be a bank which wants
to grand a consumer credit.
The bank requests information about the consumer from a
credit bureau in order to assess the consumer's credit
default risk.
Now the bank wants to predict the consumer's credit
default risk based on information the bank has about the
consumer.
If the credit default risk is very high or very low the
bank can save money not making a request to the credit
bureau for this consumer.
The optimal threshold for the abstaining classifier making
the prediction about the credit default risk can easily be
expressed by a reward function.
Every correct decision saves the bank the money the request
to the credit bureau costs.
Every miss-classification costs the bank either the amount
of money it would gain by granting the credit, or the
money it loses by giving a credit to somebody that does not
pay the rates.
Abstention cost is the cost of making a request to the
credit bureau.

Using a reward function---like in the example
above---instead of a cost function has an advantage in
readability. One can easily assess the gain of introducing
the abstaining classifier to the process.
Is the reward generated by the abstaining classifier higher
than zero, the process is enhanced by the abstaining
classifier.
Otherwise the abstaining classifier would produce more
cost than it would save and it is not valuable for the
bank to introduce it to its process of assessing a
consumer's credit default risk.

\section{Proposed method based on a reward function}
\label{sec:method}

\section{Experiments}

%\section{Other methods for abstaining}
%\label{sec:abs_methods}

\section{Further research}

\section{Conclusion}

\renewcommand{\appendixpagename}{}
\begin{appendices}
  \section*{Appendix}

  \section{Plots}

\end{appendices}

\bibliography{thesis.bib}

\newpage
\section*{Erklärung}
%\markboth{Erklärung}{Erklärung}\addcontentsline{toc}{section}{Erklärung}
Ich versichere, die von mir vorgelegte Arbeit
selbstst\"andig verfasst zu haben.
Alle Stellen, die w\"ortlich oder sinngem\"a{\ss} aus
ver\"offentlichten oder nicht ver\"offentlichten Arbeiten
anderer oder der Verfasserin/des Verfassers selbst
entnommen sind, habe ich als entnommen kenntlich gemacht.
S\"amtliche Quellen und Hilfsmittel, die ich für die Arbeit
benutzt habe, sind angegeben.
Die Arbeit hat mit gleichem Inhalt bzw. in wesentlichen
Teilen noch keiner anderen Pr\"ufungsbeh\"orde vorgelegen.

~\\
~\\
\noindent
\rule{0.35\textwidth}{0.4pt}
\hspace*{3cm}
\rule{0.45\textwidth}{0.4pt}
\newline
Ort, Datum	\hspace*{6.3cm}	Rechtsverbindliche Unterschrift
\end{document}
